希望 Sebastian 在说朴素贝叶斯非常适合文本时，更清楚地表达了他的意思。对于这一具体问题，朴素贝叶斯不仅更快，而且通常比 SVM 更出色。当然，SVM 更适合许多其他问题。你在第一次求解问题时就知道该尝试哪个算法，这是机器学习艺术和科学性的一个体现。除了选择算法外，视你尝试的算法而定，你还需要考虑相应的参数调整以及过拟合的可能性（特别是在你没有大量训练数据的情况下）。

我们通常建议你尝试一些不同的算法来求解每个问题。调整参数的工作量很大，但你现在只需要听完这堂课，我们将向你介绍 GridCV，一种几乎能自动查找最优参数调整的优秀 sklearn 工具。

SVM参数

经常用到sklearn中的SVC函数，这里把文档中的参数翻译了一些，以备不时之需。

本身这个函数也是基于libsvm实现的，所以在参数设置上有很多相似的地方。（PS: libsvm中的二次规划问题的解决算法是SMO）。
sklearn.svm.SVC(C=1.0, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, probability=False,

tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=None,random_state=None)

参数：

l  C：C-SVC的惩罚参数C?默认值是1.0

C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。

l  kernel ：核函数，默认是rbf，可以是‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’ 

  　　0 – 线性：u'v

 　　 1 – 多项式：(gamma*u'*v + coef0)^degree

  　　2 – RBF函数：exp(-gamma|u-v|^2)

  　　3 –sigmoid：tanh(gamma*u'*v + coef0)

l  degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。

l  gamma ： ‘rbf’,‘poly’ 和‘sigmoid’的核函数参数。默认是’auto’，则会选择1/n_features

l  coef0 ：核函数的常数项。对于‘poly’和 ‘sigmoid’有用。

l  probability ：是否采用概率估计？.默认为False

l  shrinking ：是否采用shrinking heuristic方法，默认为true

l  tol ：停止训练的误差值大小，默认为1e-3

l  cache_size ：核函数cache缓存大小，默认为200

l  class_weight ：类别的权重，字典形式传递。设置第几类的参数C为weight*C(C-SVC中的C)

l  verbose ：允许冗余输出？

l  max_iter ：最大迭代次数。-1为无限制。

l  decision_function_shape ：‘ovo’, ‘ovr’ or None, default=None3

l  random_state ：数据洗牌时的种子值，int值

主要调节的参数有：C、kernel、degree、gamma、coef0。
